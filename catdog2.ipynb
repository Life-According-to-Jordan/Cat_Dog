{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading packages\n",
    "import PIL\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.applications import imagenet_utils\n",
    "from keras import optimizers\n",
    "from ipykernel import kernelapp as app\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#file path for images\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# used to rescale the pixel values from [0, 255] to [0, 1] interval\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# automagically retrieve images and their classes for train and validation sets\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=16,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolutional neural net \n",
    "\n",
    "#layer 1\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(img_width, img_height,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#layer 2\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#layer 3\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#paramters\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model parameters\n",
    "\n",
    "#iterations\n",
    "epochs = 10\n",
    "\n",
    "#training data size\n",
    "nb_train_samples = 200\n",
    "\n",
    "#validation data size \n",
    "validation_steps = 50\n",
    "\n",
    "#steps per iteration\n",
    "steps_per_epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=10, steps_per_epoch=12, validation_data=<keras.pre..., validation_steps=50)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.4022 - acc: 0.8438 - val_loss: 0.4554 - val_acc: 0.7819\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.4909 - acc: 0.7552 - val_loss: 0.4539 - val_acc: 0.7900\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.4934 - acc: 0.7552 - val_loss: 0.5731 - val_acc: 0.7169\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.5279 - acc: 0.7344 - val_loss: 0.4949 - val_acc: 0.7825\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.4507 - acc: 0.8125 - val_loss: 0.4601 - val_acc: 0.7913\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.4533 - acc: 0.8073 - val_loss: 0.5189 - val_acc: 0.7688\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.4960 - acc: 0.7500 - val_loss: 0.4919 - val_acc: 0.7794\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.4400 - acc: 0.8281 - val_loss: 0.4697 - val_acc: 0.7850\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.4401 - acc: 0.8594 - val_loss: 0.4883 - val_acc: 0.7812\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.5722 - acc: 0.7448 - val_loss: 0.5662 - val_acc: 0.7338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x120949588>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch = nb_train_samples,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch   = steps_per_epoch,\n",
    "        validation_data   = validation_generator,\n",
    "        validation_steps  = validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save weights for later use \n",
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5661619114875793, 0.73375]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate model \n",
    "model.evaluate_generator(validation_generator, validation_steps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SP_chatbot",
   "language": "python",
   "name": "sp_chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
