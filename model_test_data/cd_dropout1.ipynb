{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jordan/Desktop/CatDog\n"
     ]
    }
   ],
   "source": [
    "cd desktop/catdog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:87: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=10, steps_per_epoch=125, validation_data=<keras.pre..., validation_steps=400)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 143s 1s/step - loss: 0.7087 - acc: 0.5165 - val_loss: 0.6987 - val_acc: 0.4998\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 137s 1s/step - loss: 0.6857 - acc: 0.5650 - val_loss: 0.6714 - val_acc: 0.5684\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 144s 1s/step - loss: 0.6462 - acc: 0.6335 - val_loss: 0.6083 - val_acc: 0.6703\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 137s 1s/step - loss: 0.6071 - acc: 0.6780 - val_loss: 0.5717 - val_acc: 0.7080\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 140s 1s/step - loss: 0.5824 - acc: 0.7090 - val_loss: 0.6319 - val_acc: 0.6398\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 140s 1s/step - loss: 0.5619 - acc: 0.7090 - val_loss: 0.5416 - val_acc: 0.7298\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 148s 1s/step - loss: 0.5215 - acc: 0.7395 - val_loss: 0.5260 - val_acc: 0.7331\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 146s 1s/step - loss: 0.5335 - acc: 0.7405 - val_loss: 0.5255 - val_acc: 0.7402\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 142s 1s/step - loss: 0.5063 - acc: 0.7435 - val_loss: 0.4993 - val_acc: 0.7617\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 152s 1s/step - loss: 0.4897 - acc: 0.7605 - val_loss: 0.5161 - val_acc: 0.7522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5162273723552637, 0.7527446675031367]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import PIL\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import imagenet_utils\n",
    "from keras import optimizers\n",
    "from ipykernel import kernelapp as app\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "# used to rescale the pixel values from [0, 255] to [0, 1] interval\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# automagically retrieve images and their classes for train and validation sets\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=16,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "#layer 1\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(img_width, img_height,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "#layer 2\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "#layer 3\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "#paramters\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.000001))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adagrad',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#model parameters\n",
    "\n",
    "#iterations\n",
    "epochs = 10\n",
    "\n",
    "#training data size\n",
    "nb_train_samples = 2000\n",
    "\n",
    "#validation data size \n",
    "validation_steps = 400\n",
    "\n",
    "#steps per iteration\n",
    "steps_per_epoch = 125\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch = nb_train_samples,\n",
    "        epochs            = epochs,\n",
    "        steps_per_epoch   = steps_per_epoch,\n",
    "        validation_data   = validation_generator,\n",
    "        validation_steps  = validation_steps)\n",
    "\n",
    "model.evaluate_generator(validation_generator, validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SP_chatbot",
   "language": "python",
   "name": "sp_chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
