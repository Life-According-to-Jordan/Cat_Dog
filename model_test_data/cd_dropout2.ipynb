{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jordan/Desktop/CatDog\n"
     ]
    }
   ],
   "source": [
    "cd desktop/catdog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:86: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=10, steps_per_epoch=125, validation_data=<keras.pre..., validation_steps=400)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 392s 3s/step - loss: 0.6928 - acc: 0.5140 - val_loss: 0.6956 - val_acc: 0.4998\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 358s 3s/step - loss: 0.6742 - acc: 0.5825 - val_loss: 0.6438 - val_acc: 0.6374\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 304s 2s/step - loss: 0.6446 - acc: 0.6430 - val_loss: 0.6342 - val_acc: 0.6495\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 305s 2s/step - loss: 0.6122 - acc: 0.6710 - val_loss: 0.5871 - val_acc: 0.7009\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 365s 3s/step - loss: 0.6003 - acc: 0.6720 - val_loss: 0.5836 - val_acc: 0.7072\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 299s 2s/step - loss: 0.5480 - acc: 0.7200 - val_loss: 0.5208 - val_acc: 0.7438\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 298s 2s/step - loss: 0.5313 - acc: 0.7350 - val_loss: 0.5048 - val_acc: 0.7549\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 296s 2s/step - loss: 0.5141 - acc: 0.7505 - val_loss: 0.5354 - val_acc: 0.7402\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 302s 2s/step - loss: 0.5125 - acc: 0.7535 - val_loss: 0.4975 - val_acc: 0.7557\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 291s 2s/step - loss: 0.5046 - acc: 0.7610 - val_loss: 0.5577 - val_acc: 0.7224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.555871954227481, 0.7224749058971142]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import PIL\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import imagenet_utils\n",
    "from keras import optimizers\n",
    "from ipykernel import kernelapp as app\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "# used to rescale the pixel values from [0, 255] to [0, 1] interval\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# automagically retrieve images and their classes for train and validation sets\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=16,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "#layer 1\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(img_width, img_height,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "#layer 2\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "#layer 3\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "#paramters\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#model parameters\n",
    "\n",
    "#iterations\n",
    "epochs = 10\n",
    "\n",
    "#training data size\n",
    "nb_train_samples = 2000\n",
    "\n",
    "#validation data size \n",
    "validation_steps = 400\n",
    "\n",
    "#steps per iteration\n",
    "steps_per_epoch = 125\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch = nb_train_samples,\n",
    "        epochs            = epochs,\n",
    "        steps_per_epoch   = steps_per_epoch,\n",
    "        validation_data   = validation_generator,\n",
    "        validation_steps  = validation_steps)\n",
    "\n",
    "model.evaluate_generator(validation_generator, validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SP_chatbot",
   "language": "python",
   "name": "sp_chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
