{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jordan/Desktop/CatDog\n"
     ]
    }
   ],
   "source": [
    "cd desktop/catdog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:85: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=10, steps_per_epoch=125, validation_data=<keras.pre..., validation_steps=400)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 346s 3s/step - loss: 0.6948 - acc: 0.5050 - val_loss: 0.6918 - val_acc: 0.5746\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 452s 4s/step - loss: 0.6917 - acc: 0.5245 - val_loss: 0.6890 - val_acc: 0.5556\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 394s 3s/step - loss: 0.6808 - acc: 0.5715 - val_loss: 0.6646 - val_acc: 0.6091\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 384s 3s/step - loss: 0.6679 - acc: 0.5970 - val_loss: 0.6436 - val_acc: 0.6455\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 345s 3s/step - loss: 0.6484 - acc: 0.6290 - val_loss: 0.6372 - val_acc: 0.6599\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 346s 3s/step - loss: 0.6513 - acc: 0.6180 - val_loss: 0.6222 - val_acc: 0.6638\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 361s 3s/step - loss: 0.6497 - acc: 0.6255 - val_loss: 0.6137 - val_acc: 0.6719\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 433s 3s/step - loss: 0.6088 - acc: 0.6730 - val_loss: 0.5796 - val_acc: 0.6937\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 329s 3s/step - loss: 0.5907 - acc: 0.6930 - val_loss: 0.6111 - val_acc: 0.6590\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 339s 3s/step - loss: 0.5928 - acc: 0.6965 - val_loss: 0.5535 - val_acc: 0.7160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5538021280445449, 0.7164366373902133]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PIL\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import imagenet_utils\n",
    "from keras import optimizers\n",
    "from ipykernel import kernelapp as app\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "# used to rescale the pixel values from [0, 255] to [0, 1] interval\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# automagically retrieve images and their classes for train and validation sets\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=16,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "#layer 1\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(img_width, img_height,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "#layer 2\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "#layer 3\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "#paramters\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adamax',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#model parameters\n",
    "\n",
    "#iterations\n",
    "epochs = 10\n",
    "\n",
    "#training data size\n",
    "nb_train_samples = 2000\n",
    "\n",
    "#validation data size \n",
    "validation_steps = 400\n",
    "\n",
    "#steps per iteration\n",
    "steps_per_epoch = 125\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch = nb_train_samples,\n",
    "        epochs            = epochs,\n",
    "        steps_per_epoch   = steps_per_epoch,\n",
    "        validation_data   = validation_generator,\n",
    "        validation_steps  = validation_steps)\n",
    "\n",
    "model.evaluate_generator(validation_generator, validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SP_chatbot",
   "language": "python",
   "name": "sp_chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
