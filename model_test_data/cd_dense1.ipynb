{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jordan/Desktop/CatDog\n"
     ]
    }
   ],
   "source": [
    "cd desktop/catdog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:94: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=10, steps_per_epoch=125, validation_data=<keras.pre..., validation_steps=400)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 408s 3s/step - loss: 0.6959 - acc: 0.5065 - val_loss: 0.6926 - val_acc: 0.5089\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 349s 3s/step - loss: 0.6925 - acc: 0.5185 - val_loss: 0.6931 - val_acc: 0.5013\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 300s 2s/step - loss: 0.6928 - acc: 0.5150 - val_loss: 0.6913 - val_acc: 0.5327\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 309s 2s/step - loss: 0.6890 - acc: 0.5485 - val_loss: 0.6936 - val_acc: 0.5003\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 373s 3s/step - loss: 0.6942 - acc: 0.4870 - val_loss: 0.6914 - val_acc: 0.5678\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 302s 2s/step - loss: 0.6955 - acc: 0.5145 - val_loss: 0.6934 - val_acc: 0.4985\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 301s 2s/step - loss: 0.6937 - acc: 0.5060 - val_loss: 0.6932 - val_acc: 0.5001\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 294s 2s/step - loss: 0.6933 - acc: 0.4940 - val_loss: 0.6931 - val_acc: 0.4998\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 301s 2s/step - loss: 0.6932 - acc: 0.5065 - val_loss: 0.6930 - val_acc: 0.5005\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 286s 2s/step - loss: 0.6925 - acc: 0.5165 - val_loss: 0.6914 - val_acc: 0.4978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6914012163615735, 0.4981179422835634]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PIL\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import imagenet_utils\n",
    "from keras import optimizers\n",
    "from ipykernel import kernelapp as app\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "# used to rescale the pixel values from [0, 255] to [0, 1] interval\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# automagically retrieve images and their classes for train and validation sets\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=16,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "#layer 1\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(img_width, img_height,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "#layer 2\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "#layer 3\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "#paramters\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(48))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#model parameters\n",
    "\n",
    "#iterations\n",
    "epochs = 10\n",
    "\n",
    "#training data size\n",
    "nb_train_samples = 2000\n",
    "\n",
    "#validation data size \n",
    "validation_steps = 400\n",
    "\n",
    "#steps per iteration\n",
    "steps_per_epoch = 125\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch = nb_train_samples,\n",
    "        epochs            = epochs,\n",
    "        steps_per_epoch   = steps_per_epoch,\n",
    "        validation_data   = validation_generator,\n",
    "        validation_steps  = validation_steps)\n",
    "\n",
    "model.evaluate_generator(validation_generator, validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SP_chatbot",
   "language": "python",
   "name": "sp_chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
