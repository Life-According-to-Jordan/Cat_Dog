{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jordan/Desktop/CatDog\n"
     ]
    }
   ],
   "source": [
    "cd desktop/catdog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:87: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=10, steps_per_epoch=125, validation_data=<keras.pre..., validation_steps=400)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 239s 2s/step - loss: 0.7062 - acc: 0.5135 - val_loss: 0.6904 - val_acc: 0.4986\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 231s 2s/step - loss: 0.6896 - acc: 0.5410 - val_loss: 0.6774 - val_acc: 0.5569\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 224s 2s/step - loss: 0.6834 - acc: 0.5675 - val_loss: 0.6668 - val_acc: 0.6011\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 10947s 88s/step - loss: 0.6604 - acc: 0.6130 - val_loss: 0.6426 - val_acc: 0.6371\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 62788s 502s/step - loss: 0.6452 - acc: 0.6180 - val_loss: 0.6392 - val_acc: 0.6466\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 13296s 106s/step - loss: 0.6339 - acc: 0.6495 - val_loss: 0.6072 - val_acc: 0.6681\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 1910s 15s/step - loss: 0.6184 - acc: 0.6705 - val_loss: 0.6005 - val_acc: 0.6670\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 258s 2s/step - loss: 0.5859 - acc: 0.6975 - val_loss: 0.5723 - val_acc: 0.6986\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 263s 2s/step - loss: 0.5797 - acc: 0.6980 - val_loss: 0.5675 - val_acc: 0.6971\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 231s 2s/step - loss: 0.5835 - acc: 0.6890 - val_loss: 0.5563 - val_acc: 0.7211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5558678334674692, 0.7206712672521958]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import PIL\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import imagenet_utils\n",
    "from keras import optimizers\n",
    "from ipykernel import kernelapp as app\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "# used to rescale the pixel values from [0, 255] to [0, 1] interval\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# automagically retrieve images and their classes for train and validation sets\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=16,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "#layer 1\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(img_width, img_height,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "#layer 2\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "#layer 3\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "#paramters\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adagrad',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#model parameters\n",
    "\n",
    "#iterations\n",
    "epochs = 10\n",
    "\n",
    "#training data size\n",
    "nb_train_samples = 2000\n",
    "\n",
    "#validation data size \n",
    "validation_steps = 400\n",
    "\n",
    "#steps per iteration\n",
    "steps_per_epoch = 125\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch = nb_train_samples,\n",
    "        epochs            = epochs,\n",
    "        steps_per_epoch   = steps_per_epoch,\n",
    "        validation_data   = validation_generator,\n",
    "        validation_steps  = validation_steps)\n",
    "\n",
    "model.evaluate_generator(validation_generator, validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SP_chatbot",
   "language": "python",
   "name": "sp_chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
